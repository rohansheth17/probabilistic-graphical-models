{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "AML Project 2 Task 2.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFyOwow-fNvL",
        "colab_type": "text"
      },
      "source": [
        "# TASK 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5gQTI6tfNvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pgmpy.factors.discrete import TabularCPD\n",
        "from pgmpy.models import BayesianModel\n",
        "from pgmpy.sampling import BayesianModelSampling\n",
        "from pgmpy.estimators import K2Score\n",
        "from pgmpy.estimators import HillClimbSearch\n",
        "\n",
        "# and_data = pd.read_csv('AND_features.csv',header=0,index_col=0)\n",
        "# and_data.drop(['ImageId'],inplace=True,axis=1,errors='ignore')\n",
        "# print(and_data)\n",
        "# hill_climb = HillClimbSearch(and_data,scoring_method=K2Score(and_data))\n",
        "# bestmodel = hill_climb.estimate()\n",
        "# print(bestmodel.edges())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_KztvZkfNvV",
        "colab_type": "code",
        "colab": {},
        "outputId": "30452b54-d95a-43b5-f1e1-1f8cc226367b"
      },
      "source": [
        "fifteenfeatures_data = pd.read_csv('15featuresnew.csv',header=0,index_col=0)\n",
        "fifteenfeatures_data.drop(['imagename'],inplace=True,axis=1,errors='ignore')\n",
        "print(fifteenfeatures_data)\n",
        "hill_climb = HillClimbSearch(fifteenfeatures_data,scoring_method=K2Score(fifteenfeatures_data))\n",
        "bestmodel = hill_climb.estimate()\n",
        "print(bestmodel.edges())\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('f1', 'f5'), ('f1', 'f2'), ('f3', 'f7'), ('f3', 'f1'), ('f3', 'f12'), ('f3', 'f2'), ('f3', 'f13'), ('f3', 'f9'), ('f4', 'f3'), ('f4', 'f6'), ('f4', 'f7'), ('f4', 'f1'), ('f5', 'f10'), ('f5', 'f13'), ('f6', 'f13'), ('f6', 'f2'), ('f6', 'f9'), ('f6', 'f10'), ('f6', 'f5'), ('f7', 'f6'), ('f7', 'f8'), ('f9', 'f1'), ('f11', 'f15'), ('f11', 'f14'), ('f11', 'f4'), ('f11', 'f12'), ('f11', 'f6'), ('f11', 'f3'), ('f11', 'f10'), ('f12', 'f6'), ('f12', 'f13'), ('f12', 'f5'), ('f12', 'f7'), ('f12', 'f9'), ('f14', 'f4'), ('f14', 'f10'), ('f14', 'f3'), ('f14', 'f12'), ('f14', 'f15'), ('f15', 'f10'), ('f15', 'f2'), ('f15', 'f4')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhtk3srxfNvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BayesianModel([('f1_x', 'f5_x'), ('f1_x', 'f2_x'), ('f3_x', 'f7_x'), ('f3_x', 'f1_x'), ('f3_x', 'f12_x'), ('f3_x', 'f2_x'), ('f3_x', 'f13_x'), ('f3_x', 'f9_x'), ('f4_x', 'f3_x'), ('f4_x', 'f6_x'), ('f4_x', 'f7_x'), ('f4_x', 'f1_x'), ('f5_x', 'f10_x'), ('f5_x', 'f13_x'), ('f6_x', 'f13_x'), ('f6_x', 'f2_x'), ('f6_x', 'f9_x'), ('f6_x', 'f10_x'), ('f6_x', 'f5_x'), ('f7_x', 'f6_x'), ('f7_x', 'f8_x'), ('f9_x', 'f1_x'), ('f11_x', 'f15_x'), ('f11_x', 'f14_x'), ('f11_x', 'f4_x'), ('f11_x', 'f12_x'), ('f11_x', 'f6_x'), ('f11_x', 'f3_x'), ('f11_x', 'f10_x'), ('f12_x', 'f6_x'), ('f12_x', 'f13_x'), ('f12_x', 'f5_x'), ('f12_x', 'f7_x'), ('f12_x', 'f9_x'), ('f14_x', 'f4_x'), ('f14_x', 'f10_x'), ('f14_x', 'f3_x'), ('f14_x', 'f12_x'), ('f14_x', 'f15_x'), \n",
        "                       ('f15_x', 'f10_x'), ('f15_x', 'f2_x'), ('f15_x', 'f4_x'),('f1_y', 'f5_y'), ('f1_y', 'f2_y'), ('f3_y', 'f7_y'), ('f3_y', 'f1_y'), ('f3_y', 'f12_y'), ('f3_y', 'f2_y'), ('f3_y', 'f13_y'), ('f3_y', 'f9_y'), ('f4_y', 'f3_y'), ('f4_y', 'f6_y'), ('f4_y', 'f7_y'), ('f4_y', 'f1_y'), ('f5_y', 'f10_y'), ('f5_y', 'f13_y'), ('f6_y', 'f13_y'), ('f6_y', 'f2_y'), ('f6_y', 'f9_y'), ('f6_y', 'f10_y'), ('f6_y', 'f5_y'), ('f7_y', 'f6_y'), ('f7_y', 'f8_y'), ('f9_y', 'f1_y'), ('f11_y', 'f15_y'), ('f11_y', 'f14_y'), ('f11_y', 'f4_y'), ('f11_y', 'f12_y'), ('f11_y', 'f6_y'), ('f11_y', 'f3_y'), ('f11_y', 'f10_y'), ('f12_y', 'f6_y'), ('f12_y', 'f13_y'), ('f12_y', 'f5_y'), ('f12_y', 'f7_y'), ('f12_y', 'f9_y'), ('f14_y', 'f4_y'), ('f14_y', 'f10_y'), ('f14_y', 'f3_y'), ('f14_y', 'f12_y'), ('f14_y', 'f15_y'), \n",
        "                       ('f15_y', 'f10_y'), ('f15_y', 'f2_y'), ('f15_y', 'f4_y'),('f4_x','label'),('f6_x','label'),('f12_x','label'),('f14_x','label'),('f15_x','label'),('f4_y','label'),('f6_y','label'),('f12_y','label'),('f14_y','label'),('f15_y','label')]) \n",
        "\n",
        "\n",
        "# model.add_node('label')\n",
        "# model.add_edges_from([('f3_x','label'),('f4_x','label'),('f6_x','label'),('f7_x','label'),('f10_x','label'),('f12_x','label'),('f14_x','label'),('f15_x','label'),('f3_y','label'),('f4_y','label'),('f6_y','label'),('f7_y','label'),('f10_y','label'),('f12_y','label'),('f14_y','label'),('f15_y','label')])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hao3sFdLfNvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fifteenfeaturess_data = pd.read_csv('15featuresnew.csv',header=0,index_col=0)\n",
        "fifteenfeaturess_data['f1']-=1\n",
        "fifteenfeaturess_data['f2']-=1\n",
        "fifteenfeaturess_data['f3']-=1\n",
        "fifteenfeaturess_data['f4']-=1\n",
        "fifteenfeaturess_data['f5']-=1\n",
        "fifteenfeaturess_data['f6']-=1\n",
        "fifteenfeaturess_data['f7']-=1\n",
        "fifteenfeaturess_data['f8']-=1\n",
        "fifteenfeaturess_data['f9']-=1\n",
        "fifteenfeaturess_data['f10']-=1\n",
        "fifteenfeaturess_data['f11']-=1\n",
        "fifteenfeaturess_data['f12']-=1\n",
        "fifteenfeaturess_data['f13']-=1\n",
        "fifteenfeaturess_data['f14']-=1\n",
        "fifteenfeaturess_data['f15']-=1\n",
        "# print(fifteenfeaturess_data)\n",
        "seen_trainingdata = pd.read_csv('dataset_seen_training_siamese.csv',header=0,index_col=0)\n",
        "seen_validationdata = pd.read_csv('dataset_seen_validation_siamese.csv',header=0,index_col=0)\n",
        "shuffled_trainingdata = pd.read_csv('dataset_shuffled_training_siamese.csv',header=0,index_col=0)\n",
        "shuffled_validationdata = pd.read_csv('dataset_shuffled_validation_siamese.csv',header=0,index_col=0)\n",
        "unseen_trainingdata = pd.read_csv('dataset_unseen_training_siamese.csv',header=0,index_col=0)\n",
        "unseen_validationdata = pd.read_csv('dataset_unseen_validation_siamese.csv',header=0,index_col=0)\n",
        "\n",
        "\n",
        "samp1= pd.merge(seen_trainingdata,fifteenfeaturess_data, left_on='right' , right_on='imagename')\n",
        "# print(samp1)\n",
        "samp2= pd.merge(samp1,fifteenfeaturess_data, left_on='left', right_on='imagename')\n",
        "samp2 = samp2.drop(samp2.columns[[0, 1, 3]], axis=1)\n",
        "samp2.drop(['imagename_y'],inplace=True,axis=1,errors='ignore')\n",
        "\n",
        "# label_data=samp2.loc[:,'label']\n",
        "# samp2 = samp2.drop(samp2.columns[[0]], axis=1)\n",
        "# # # print (samp3)\n",
        "# # # print(label_data)\n",
        "# # # pd.concat([samp3, label_data], axis=1)\n",
        "# samp2 = pd.concat([samp2, label_data], axis=1)\n",
        "# # samp4 = samp4.drop(samp4.columns[[15]], axis=1)\n",
        "# print(samp2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaYlBnGxfNvl",
        "colab_type": "code",
        "colab": {},
        "outputId": "23d0163a-1463-4761-c6cc-572745e04ec2"
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "model.fit(samp2)\n",
        "end = time.time()\n",
        "print(\"Training time: \",end-start,\"secs\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Replacing existing CPD for f10_x\n",
            "WARNING:root:Replacing existing CPD for f10_y\n",
            "WARNING:root:Replacing existing CPD for f11_x\n",
            "WARNING:root:Replacing existing CPD for f11_y\n",
            "WARNING:root:Replacing existing CPD for f12_x\n",
            "WARNING:root:Replacing existing CPD for f12_y\n",
            "WARNING:root:Replacing existing CPD for f13_x\n",
            "WARNING:root:Replacing existing CPD for f13_y\n",
            "WARNING:root:Replacing existing CPD for f14_x\n",
            "WARNING:root:Replacing existing CPD for f14_y\n",
            "WARNING:root:Replacing existing CPD for f15_x\n",
            "WARNING:root:Replacing existing CPD for f15_y\n",
            "WARNING:root:Replacing existing CPD for f1_x\n",
            "WARNING:root:Replacing existing CPD for f1_y\n",
            "WARNING:root:Replacing existing CPD for f2_x\n",
            "WARNING:root:Replacing existing CPD for f2_y\n",
            "WARNING:root:Replacing existing CPD for f3_x\n",
            "WARNING:root:Replacing existing CPD for f3_y\n",
            "WARNING:root:Replacing existing CPD for f4_x\n",
            "WARNING:root:Replacing existing CPD for f4_y\n",
            "WARNING:root:Replacing existing CPD for f5_x\n",
            "WARNING:root:Replacing existing CPD for f5_y\n",
            "WARNING:root:Replacing existing CPD for f6_x\n",
            "WARNING:root:Replacing existing CPD for f6_y\n",
            "WARNING:root:Replacing existing CPD for f7_x\n",
            "WARNING:root:Replacing existing CPD for f7_y\n",
            "WARNING:root:Replacing existing CPD for f8_x\n",
            "WARNING:root:Replacing existing CPD for f8_y\n",
            "WARNING:root:Replacing existing CPD for f9_x\n",
            "WARNING:root:Replacing existing CPD for f9_y\n",
            "WARNING:root:Replacing existing CPD for label\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training time:  5.6895740032196045 secs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eNkFl6ZfNvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samp3= pd.merge(seen_validationdata,fifteenfeaturess_data, left_on='right' , right_on='imagename')\n",
        "samp4= pd.merge(samp3,fifteenfeaturess_data, left_on='left', right_on='imagename')\n",
        "samp4 = samp4.drop(samp4.columns[[0, 1, 3]], axis=1)\n",
        "samp4.drop(['imagename_y'],inplace=True,axis=1,errors='ignore')\n",
        "# label_data1=samp4.loc[:,'label']\n",
        "# samp4 = samp4.drop(samp4.columns[[0]], axis=1)\n",
        "# # # pd.concat([samp7, label_data1], axis=1)\n",
        "# samp4 = pd.concat([samp4, label_data1], axis=1)\n",
        "# # samp8 = samp8.drop(samp8.columns[[15]], axis=1)\n",
        "# print(samp4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDfYJue4fNvt",
        "colab_type": "code",
        "colab": {},
        "outputId": "953d2f3c-91a9-42e3-fd0c-50cd83fbbef7"
      },
      "source": [
        "from pgmpy.inference import VariableElimination\n",
        "result ={}\n",
        "results={}\n",
        "start= time.time()\n",
        "# bp = BeliefPropagation(model)\n",
        "infer = VariableElimination(model)\n",
        "for i in range(0,894):\n",
        "    l = list(samp4.iloc[i,1:31])\n",
        "    res = infer.query(['label'],evidence={'f1_x':l[0],'f2_x':l[1],'f3_x':l[2],'f4_x':l[3],'f5_x':l[4],'f6_x':l[5],'f7_x':l[6],'f8_x':l[7],'f9_x':l[8],\n",
        "                                        'f10_x':l[9],'f11_x':l[10],'f12_x':l[11],'f13_x':l[12],'f14_x':l[13],'f15_x':l[14],\n",
        "                                       'f1_y':l[15],'f2_y':l[16],'f3_y':l[17],'f4_y':l[18],'f5_y':l[19],'f6_y':l[20],'f7_y':l[21],'f8_y':l[22],'f9_y':l[23],\n",
        "                                        'f10_y':l[24],'f11_y':l[25],'f12_y':l[26],'f13_y':l[27],'f14_y':l[28],'f15_y':l[29]})['label']\n",
        "#     res = bp.map_query(variables=['label'],evidence={'f1_x':l[0],'f2_x':l[1],'f3_x':l[2],'f4_x':l[3],'f5_x':l[4],'f6_x':l[5],'f7_x':l[6],'f8_x':l[7],'f9_x':l[8],\n",
        "#                                         'f10_x':l[9],'f11_x':l[10],'f12_x':l[11],'f13_x':l[12],'f14_x':l[13],'f15_x':l[14],\n",
        "#                                        'f1_y':l[15],'f2_y':l[16],'f3_y':l[17],'f4_y':l[18],'f5_y':l[19],'f6_y':l[20],'f7_y':l[21],'f8_y':l[22],'f9_y':l[23],\n",
        "#                                         'f10_y':l[24],'f11_y':l[25],'f12_y':l[26],'f13_y':l[27],'f14_y':l[28],'f15_y':l[29]}).get('label')\n",
        "    results[i] = model.predict(pd.DataFrame(samp4.iloc[i,1:31]).T)\n",
        "    result[i] = res\n",
        "end = time.time()\n",
        "print(\"Prediction Time: \",end-start,\"secs.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction Time:  5324.591943264008 secs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACP-pelTfNvx",
        "colab_type": "code",
        "colab": {},
        "outputId": "78383b42-0fd6-48de-e452-14bb47db8f8c"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "ans =[]\n",
        "for i,j in zip(results,result):\n",
        "    ans.extend(list(results[i]['label']))\n",
        "#     print(result[j].values)\n",
        "print(ans)\n",
        "print(accuracy_score(samp4['label'],ans))\n",
        "\n",
        "\n",
        "# print(samp4['label'][893])\n",
        "\n",
        "count=0\n",
        "for index, row in samp4.iterrows():\n",
        "    if(row[\"label\"]==ans[index]):\n",
        "        count += 1\n",
        " \n",
        "index = index+1\n",
        "print(\"Validation Accuracy: \",(count/index)*100,\"%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1]\n",
            "0.6487695749440716\n",
            "Validation Accuracy:  64.87695749440716 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm9XNa-5fNv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Similary we repeat the above procedure for shuffled and unseen data-sets.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhcR6RpNfNv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samp1= pd.merge(unseen_trainingdata,fifteenfeaturess_data, left_on='right' , right_on='imagename')\n",
        "# print(samp1)\n",
        "samp2= pd.merge(samp1,fifteenfeaturess_data, left_on='left', right_on='imagename')\n",
        "samp2 = samp2.drop(samp2.columns[[0, 1, 3]], axis=1)\n",
        "samp2.drop(['imagename_y'],inplace=True,axis=1,errors='ignore')\n",
        "\n",
        "\n",
        "samp3= pd.merge(unseen_validationdata,fifteenfeaturess_data, left_on='right' , right_on='imagename')\n",
        "samp4= pd.merge(samp3,fifteenfeaturess_data, left_on='left', right_on='imagename')\n",
        "samp4 = samp4.drop(samp4.columns[[0, 1, 3]], axis=1)\n",
        "samp4.drop(['imagename_y'],inplace=True,axis=1,errors='ignore')\n",
        "\n",
        "\n",
        "from pgmpy.inference import VariableElimination\n",
        "result ={}\n",
        "results={}\n",
        "start= time.time()\n",
        "# bp = BeliefPropagation(model)\n",
        "infer = VariableElimination(model)\n",
        "for i in range(0,894):\n",
        "    l = list(samp4.iloc[i,1:31])\n",
        "    res = infer.query(['label'],evidence={'f1_x':l[0],'f2_x':l[1],'f3_x':l[2],'f4_x':l[3],'f5_x':l[4],'f6_x':l[5],'f7_x':l[6],'f8_x':l[7],'f9_x':l[8],\n",
        "                                        'f10_x':l[9],'f11_x':l[10],'f12_x':l[11],'f13_x':l[12],'f14_x':l[13],'f15_x':l[14],\n",
        "                                       'f1_y':l[15],'f2_y':l[16],'f3_y':l[17],'f4_y':l[18],'f5_y':l[19],'f6_y':l[20],'f7_y':l[21],'f8_y':l[22],'f9_y':l[23],\n",
        "                                        'f10_y':l[24],'f11_y':l[25],'f12_y':l[26],'f13_y':l[27],'f14_y':l[28],'f15_y':l[29]})['label']\n",
        "#     res = bp.map_query(variables=['label'],evidence={'f1_x':l[0],'f2_x':l[1],'f3_x':l[2],'f4_x':l[3],'f5_x':l[4],'f6_x':l[5],'f7_x':l[6],'f8_x':l[7],'f9_x':l[8],\n",
        "#                                         'f10_x':l[9],'f11_x':l[10],'f12_x':l[11],'f13_x':l[12],'f14_x':l[13],'f15_x':l[14],\n",
        "#                                        'f1_y':l[15],'f2_y':l[16],'f3_y':l[17],'f4_y':l[18],'f5_y':l[19],'f6_y':l[20],'f7_y':l[21],'f8_y':l[22],'f9_y':l[23],\n",
        "#                                         'f10_y':l[24],'f11_y':l[25],'f12_y':l[26],'f13_y':l[27],'f14_y':l[28],'f15_y':l[29]}).get('label')\n",
        "    results[i] = model.predict(pd.DataFrame(samp4.iloc[i,1:31]).T)\n",
        "    result[i] = res\n",
        "end = time.time()\n",
        "print(\"Prediction Time: \",end-start,\"secs.\")\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "ans =[]\n",
        "for i,j in zip(results,result):\n",
        "    ans.extend(list(results[i]['label']))\n",
        "#     print(result[j].values)\n",
        "print(ans)\n",
        "print(accuracy_score(samp4['label'],ans))\n",
        "\n",
        "\n",
        "# print(samp4['label'][893])\n",
        "\n",
        "count=0\n",
        "for index, row in samp4.iterrows():\n",
        "    if(row[\"label\"]==ans[index]):\n",
        "        count += 1\n",
        " \n",
        "index = index+1\n",
        "print(\"Validation Accuracy: \",(count/index)*100,\"%\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSat9qT6fNv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samp1= pd.merge(shuffled_trainingdata,fifteenfeaturess_data, left_on='right' , right_on='imagename')\n",
        "# print(samp1)\n",
        "samp2= pd.merge(samp1,fifteenfeaturess_data, left_on='left', right_on='imagename')\n",
        "samp2 = samp2.drop(samp2.columns[[0, 1, 3]], axis=1)\n",
        "samp2.drop(['imagename_y'],inplace=True,axis=1,errors='ignore')\n",
        "\n",
        "\n",
        "samp3= pd.merge(shuffled_validationdata,fifteenfeaturess_data, left_on='right' , right_on='imagename')\n",
        "samp4= pd.merge(samp3,fifteenfeaturess_data, left_on='left', right_on='imagename')\n",
        "samp4 = samp4.drop(samp4.columns[[0, 1, 3]], axis=1)\n",
        "samp4.drop(['imagename_y'],inplace=True,axis=1,errors='ignore')\n",
        "\n",
        "\n",
        "from pgmpy.inference import VariableElimination\n",
        "result ={}\n",
        "results={}\n",
        "start= time.time()\n",
        "# bp = BeliefPropagation(model)\n",
        "infer = VariableElimination(model)\n",
        "for i in range(0,894):\n",
        "    l = list(samp4.iloc[i,1:31])\n",
        "    res = infer.query(['label'],evidence={'f1_x':l[0],'f2_x':l[1],'f3_x':l[2],'f4_x':l[3],'f5_x':l[4],'f6_x':l[5],'f7_x':l[6],'f8_x':l[7],'f9_x':l[8],\n",
        "                                        'f10_x':l[9],'f11_x':l[10],'f12_x':l[11],'f13_x':l[12],'f14_x':l[13],'f15_x':l[14],\n",
        "                                       'f1_y':l[15],'f2_y':l[16],'f3_y':l[17],'f4_y':l[18],'f5_y':l[19],'f6_y':l[20],'f7_y':l[21],'f8_y':l[22],'f9_y':l[23],\n",
        "                                        'f10_y':l[24],'f11_y':l[25],'f12_y':l[26],'f13_y':l[27],'f14_y':l[28],'f15_y':l[29]})['label']\n",
        "#     res = bp.map_query(variables=['label'],evidence={'f1_x':l[0],'f2_x':l[1],'f3_x':l[2],'f4_x':l[3],'f5_x':l[4],'f6_x':l[5],'f7_x':l[6],'f8_x':l[7],'f9_x':l[8],\n",
        "#                                         'f10_x':l[9],'f11_x':l[10],'f12_x':l[11],'f13_x':l[12],'f14_x':l[13],'f15_x':l[14],\n",
        "#                                        'f1_y':l[15],'f2_y':l[16],'f3_y':l[17],'f4_y':l[18],'f5_y':l[19],'f6_y':l[20],'f7_y':l[21],'f8_y':l[22],'f9_y':l[23],\n",
        "#                                         'f10_y':l[24],'f11_y':l[25],'f12_y':l[26],'f13_y':l[27],'f14_y':l[28],'f15_y':l[29]}).get('label')\n",
        "    results[i] = model.predict(pd.DataFrame(samp4.iloc[i,1:31]).T)\n",
        "    result[i] = res\n",
        "end = time.time()\n",
        "print(\"Prediction Time: \",end-start,\"secs.\")\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "ans =[]\n",
        "for i,j in zip(results,result):\n",
        "    ans.extend(list(results[i]['label']))\n",
        "#     print(result[j].values)\n",
        "print(ans)\n",
        "print(accuracy_score(samp4['label'],ans))\n",
        "\n",
        "\n",
        "# print(samp4['label'][893])\n",
        "\n",
        "count=0\n",
        "for index, row in samp4.iterrows():\n",
        "    if(row[\"label\"]==ans[index]):\n",
        "        count += 1\n",
        " \n",
        "index = index+1\n",
        "print(\"Validation Accuracy: \",(count/index)*100,\"%\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}